{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No of atoms = 6,7 (Learning rate decay used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from rdkit import RDLogger\n",
    "from chainer_chemistry import datasets\n",
    "\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filepath = datasets.get_qm9_filepath()\n",
    "\n",
    "print('dataset_filepath =', dataset_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer_chemistry.dataset.preprocessors.ggnn_preprocessor import \\\n",
    "    GGNNPreprocessor\n",
    "    \n",
    "preprocessor = GGNNPreprocessor()\n",
    "dataset, dataset_smiles = datasets.get_qm9(preprocessor, labels=None, return_smiles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dataset information...')\n",
    "print('dataset', type(dataset), len(dataset))\n",
    "\n",
    "print('smiles information...')\n",
    "print('dataset_smiles', type(dataset_smiles), len(dataset_smiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from rdkit import Chem\n",
    "import pennylane as qml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def smiles_to_graph_and_targets(smiles_list, dataset):\n",
    "    data_list = []\n",
    "    targets = []\n",
    "    for smiles, data in zip(smiles_list, dataset):\n",
    "        properties = data if len(data) > 0 else None\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "\n",
    "        atomic_nums = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
    "        aromatics = [atom.GetIsAromatic() for atom in mol.GetAtoms()]\n",
    "        hybridizations = [int(atom.GetHybridization()) for atom in mol.GetAtoms()]\n",
    "        num_hydrogens = [atom.GetTotalNumHs() for atom in mol.GetAtoms()]\n",
    "\n",
    "        x = np.column_stack([atomic_nums, aromatics, hybridizations, num_hydrogens])\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        bond_info = []\n",
    "\n",
    "        for bond in mol.GetBonds():\n",
    "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            bond_type = bond.GetBondType()\n",
    "            bond_label = {Chem.rdchem.BondType.SINGLE: 'single',\n",
    "                          Chem.rdchem.BondType.DOUBLE: 'double',\n",
    "                          Chem.rdchem.BondType.TRIPLE: 'triple',\n",
    "                          Chem.rdchem.BondType.AROMATIC: 'aromatic'}.get(bond_type, 'single')\n",
    "            bond_info.append((start, end, bond_label))\n",
    "            edge_attr.append([1 if bond_label == bl else 0 for bl in ['single', 'double', 'triple', 'aromatic']])\n",
    "            edge_index.append([start, end])\n",
    "\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, bond_info=bond_info)\n",
    "        data_list.append(data)\n",
    "\n",
    "        if properties is not None:\n",
    "            target_value = properties[2][7]  # the target is in the 7th column of the third block\n",
    "            targets.append(target_value)\n",
    "\n",
    "    targets = torch.tensor(targets, dtype=torch.float)\n",
    "    return data_list, targets\n",
    "\n",
    "def split_data(graph_data, targets, train_size, val_size):\n",
    "    print(f\"Total graphs: {len(graph_data)}, Total targets: {len(targets)}\")\n",
    "    indices = np.random.permutation(len(graph_data))\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "\n",
    "    train_data = [graph_data[i] for i in train_indices]\n",
    "    train_targets = targets[train_indices]\n",
    "    val_data = [graph_data[i] for i in val_indices]\n",
    "    val_targets = targets[val_indices]\n",
    "\n",
    "    return (train_data, train_targets), (val_data, val_targets)\n",
    "\n",
    "def filter_graphs_by_num_atoms(graph_data, targets, num_atoms=[6,7]):\n",
    "    filtered_graphs = [graph for graph in graph_data if graph.num_nodes == num_atoms]\n",
    "    filtered_targets = [targets[i] for i, graph in enumerate(graph_data) if graph.num_nodes == num_atoms]\n",
    "    return filtered_graphs, torch.tensor(filtered_targets, dtype=torch.float)\n",
    "\n",
    "def batch_processing(graph_data, targets, batch_size):\n",
    "    num_batches = len(graph_data) // batch_size\n",
    "    for i in range(num_batches):\n",
    "        batch_data = graph_data[i * batch_size: (i + 1) * batch_size]\n",
    "        batch_targets = targets[i * batch_size: (i + 1) * batch_size]\n",
    "        yield batch_data, batch_targets\n",
    "\n",
    "def quantum_encode(features, use_atomic_num=True, use_nh=False, use_aromaticity=True, use_hybridization=True):\n",
    "    encoded_params = []\n",
    "    for feature in features:\n",
    "        z, nh, aromatic, hybridization = feature.tolist()\n",
    "        ry_angle, rz_angle = 0, 0\n",
    "\n",
    "        if use_atomic_num and not use_nh and use_aromaticity and use_hybridization:\n",
    "            ry_angle = (2 * z - 7) * np.pi / 4 if z is not None else 0\n",
    "            rz_angle = (-1)**(2 * hybridization - 1) * np.pi / 6 if hybridization is not None else 0\n",
    "        elif use_atomic_num and use_nh:\n",
    "            ry_angle = (2 * z - 7) * np.pi / 4 if z is not None else 0\n",
    "            rz_angle = 2 * np.pi * nh / 5 if nh is not None else 0\n",
    "        elif use_atomic_num:\n",
    "            if z in [5, 6, 7]:\n",
    "                ry_angle = np.cos(-1 / 3)\n",
    "            if z == 6:\n",
    "                rz_angle = 2 * np.pi / 3\n",
    "            elif z == 7:\n",
    "                rz_angle = -2 * np.pi / 3\n",
    "\n",
    "        encoded_params.append([ry_angle, rz_angle])\n",
    "    return np.array(encoded_params)\n",
    "\n",
    "def default_EDU(bond_params, rzz_param, wires):\n",
    "    #if len(wires) < 2:\n",
    "        #raise ValueError(f\"Expected 'wires' to contain at least 2 elements, but got {len(wires)} elements: {wires}\")\n",
    "    \n",
    "    #print(f\"Applying EDU on wires: {wires}\")\n",
    "    \n",
    "    qml.RZ(bond_params[0], wires=wires[0])\n",
    "    qml.RX(bond_params[1], wires=wires[0])\n",
    "    qml.RZ(bond_params[0], wires=wires[1])\n",
    "    qml.RX(bond_params[1], wires=wires[1])\n",
    "    qml.CNOT(wires=wires)\n",
    "    qml.RZ(rzz_param, wires=wires[1])\n",
    "    qml.CNOT(wires=wires)\n",
    "    qml.RX(bond_params[0], wires=wires[0])\n",
    "    qml.RZ(bond_params[1], wires=wires[0])\n",
    "    qml.RX(bond_params[0], wires=wires[1])\n",
    "    qml.RZ(bond_params[1], wires=wires[1])\n",
    "\n",
    "def quantum_circuit_single(graph, layer_params):\n",
    "    num_layers = 3\n",
    "    num_atoms = graph.num_nodes\n",
    "    dev = qml.device('default.qubit', wires=num_atoms)\n",
    "\n",
    "    @qml.qnode(dev, interface='torch')\n",
    "    def circuit():\n",
    "        encoded_features = quantum_encode(graph.x)\n",
    "        for i in range(num_atoms):\n",
    "            qml.RY(encoded_features[i][0], wires=i)\n",
    "            qml.RZ(encoded_features[i][1], wires=i)\n",
    "\n",
    "        for layer in range(num_layers):\n",
    "            rzz_param = layer_params['rzz_params'][layer]\n",
    "            for i in range(num_atoms):\n",
    "                qml.U3(layer_params['theta'][layer], layer_params['phi'][layer], layer_params['omega'][layer], wires=i)\n",
    "            bond_order = ['single', 'aromatic', 'double', 'triple']\n",
    "            sorted_bonds = sorted(graph.bond_info, key=lambda x: bond_order.index(x[2]))\n",
    "            for start, end, bond_type in sorted_bonds:\n",
    "                bond_edu_params = layer_params['edu'][bond_type]\n",
    "                default_EDU(bond_edu_params, rzz_param, [start, end])\n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(num_atoms)]\n",
    "\n",
    "    qml_results = circuit()\n",
    "    return torch.stack(qml_results).float()\n",
    "\n",
    "def quantum_circuit_batch(batch_data, params):\n",
    "    results = []\n",
    "    for graph in batch_data:\n",
    "        result = quantum_circuit_single(graph, params)\n",
    "        results.append(result)\n",
    "    return torch.stack(results)\n",
    "\n",
    "\n",
    "def initialize_params(layers):\n",
    "    params = {\n",
    "        'theta': [torch.nn.Parameter(torch.rand(1), requires_grad=True) for _ in range(layers)],\n",
    "        'phi': [torch.nn.Parameter(torch.rand(1), requires_grad=True) for _ in range(layers)],\n",
    "        'omega': [torch.nn.Parameter(torch.rand(1), requires_grad=True) for _ in range(layers)],\n",
    "        'rzz_params': [torch.nn.Parameter(torch.rand(1), requires_grad=True) for _ in range(layers)],\n",
    "        'edu': {\n",
    "            'single': torch.nn.Parameter(torch.rand(2), requires_grad=True),\n",
    "            'aromatic': torch.nn.Parameter(torch.rand(2), requires_grad=True),\n",
    "            'double': torch.nn.Parameter(torch.rand(2), requires_grad=True),\n",
    "            'triple': torch.nn.Parameter(torch.rand(2), requires_grad=True)\n",
    "        }\n",
    "    }\n",
    "    return params\n",
    "\n",
    "\n",
    " \n",
    "def train_and_plot(train_data, train_targets, val_data, val_targets, batch_size, total_epochs=300, validate_every=5):\n",
    "    layers = 3\n",
    "    params = initialize_params(layers)\n",
    "\n",
    "    all_params = []\n",
    "    for key in params:\n",
    "        if isinstance(params[key], dict):\n",
    "            for subkey in params[key]:\n",
    "                all_params.append(params[key][subkey])\n",
    "        else:\n",
    "            all_params.extend(params[key])\n",
    "\n",
    "    r0 = torch.nn.Parameter(torch.tensor(0.1, requires_grad=True))\n",
    "    r1 = torch.nn.Parameter(torch.tensor(0.2, requires_grad=True))\n",
    "    all_params.extend([r0, r1])\n",
    "\n",
    "    optimizer = torch.optim.Adam(all_params, lr=0.01)  \n",
    "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)  \n",
    "\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "        total_train_loss = 0\n",
    "        train_batches = list(batch_processing(train_data, train_targets, batch_size))\n",
    "        for batch_data, batch_targets in train_batches:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = quantum_circuit_batch(batch_data, params)\n",
    "            adjusted_predictions = r0 + r1 * torch.sum(predictions, dim=1) / len(predictions[0])\n",
    "            loss = loss_func(adjusted_predictions, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        scheduler.step()  # Update the learning rate\n",
    "        epoch_train_loss = total_train_loss / len(train_batches)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {epoch_train_loss}\")\n",
    "\n",
    "        if (epoch + 1) % validate_every == 0:\n",
    "            total_val_loss = 0\n",
    "            val_batches = list(batch_processing(val_data, val_targets, batch_size))\n",
    "            for batch_data, batch_targets in val_batches:\n",
    "                predictions = quantum_circuit_batch(batch_data, params)\n",
    "                adjusted_predictions = r0 + r1 * torch.sum(predictions, dim=1) / len(predictions[0])\n",
    "                loss = loss_func(adjusted_predictions, batch_targets)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "            epoch_val_loss = total_val_loss / len(val_batches)\n",
    "            val_losses.append(epoch_val_loss)\n",
    "            print(f\"Validation Loss after Epoch {epoch+1}: {epoch_val_loss}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(validate_every, len(val_losses) * validate_every + 1, validate_every), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "graph_data, targets = smiles_to_graph_and_targets(dataset_smiles, dataset)\n",
    "filtered_graphs, filtered_targets = filter_graphs_by_num_atoms(graph_data, targets, num_atoms=6)\n",
    "assert len(filtered_graphs) >= 600, \"Not enough samples with 6 atoms\"\n",
    "selected_graphs = filtered_graphs[:600]\n",
    "selected_targets = filtered_targets[:600]\n",
    "(train_data, train_targets), (val_data, val_targets) = split_data(selected_graphs, selected_targets, 300, 300)\n",
    "train_and_plot(train_data, train_targets, val_data, val_targets, batch_size=30, total_epochs=300, validate_every=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
